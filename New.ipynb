{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "PARTS = 20\n",
    "IMAGE_SIZE = (40, 40)\n",
    "BATCH_SIZE = 66\n",
    "assert torch.cuda.is_available()\n",
    "DEVICE = torch.device('cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms\n",
    "# import random\n",
    "# random.seed(69420)\n",
    "stx, sty = 0, 0\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "upscaling = torchvision.transforms.Resize(size=IMAGE_SIZE, antialias=True)\n",
    "def CartoonNetwork(x: torch.tensor):\n",
    "    return torchvision.transforms.functional.erase(img = x, i = stx, j = sty, h = 10, w = 10, v = 0)\n",
    "dataset_transform = torchvision.transforms.Compose([to_tensor, upscaling, CartoonNetwork])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "import torchvision.datasets\n",
    "\n",
    "train = torchvision.datasets.MNIST(\n",
    "    root = \"./data\",\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = dataset_transform\n",
    ")\n",
    "\n",
    "train_parts = torch.utils.data.random_split(train, lengths=[1 / PARTS - 1e-12]*PARTS)\n",
    "print(len(train_parts))\n",
    "print(len(train_parts[0]))\n",
    "print(len(train_parts[0][0]))\n",
    "train_parts[0][0][0].shape\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(train_parts[0][0][0][0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "\n",
    "\n",
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #  1x40x40\n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            in_channels=1, out_channels=32, kernel_size=3, padding='same')\n",
    "        # 32x40x40\n",
    "        self.maxpl = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # 16x20x20\n",
    "        self.conv2 = torch.nn.Conv2d(\n",
    "            in_channels=32, out_channels=64, kernel_size=3, padding='same')\n",
    "        # 64x20x20\n",
    "        self.avgpl = torch.nn.AvgPool2d(kernel_size=4)\n",
    "        # 64x5x5\n",
    "        self.flatt = torch.nn.Flatten()\n",
    "        # 1600\n",
    "        self.line1 = torch.nn.Linear(in_features=1600, out_features=128)\n",
    "        # 128\n",
    "        self.activ = torch.nn.ReLU()\n",
    "        # 128\n",
    "        self.feats = torch.nn.Linear(in_features=128, out_features=10)\n",
    "        # 10\n",
    "        # self.softx = torch.nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activ(x)\n",
    "        x = self.maxpl(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activ(x)\n",
    "        x = self.avgpl(x)\n",
    "        x = self.flatt(x)\n",
    "        x = self.line1(x)\n",
    "        x = self.activ(x)\n",
    "        x = self.feats(x)\n",
    "        # x = self.softx(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleCNN().to(DEVICE)\n",
    "# model.load_state_dict(torch.load('./data/model_dict.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "def generate_loaders(vpart: int) -> tuple[DataLoader, DataLoader]:\n",
    "    train_dataset = ConcatDataset(train_parts[:vpart] + train_parts[vpart + 1:])\n",
    "    train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    validation_dataset = train_parts[vpart]\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size = BATCH_SIZE, shuffle=False)\n",
    "    return train_loader, validation_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "def train_epoch(loader: torch.utils.data.DataLoader, train: bool) -> tuple[int, float]:\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, y in tqdm_notebook(loader):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        output = model(x)\n",
    "        batch_loss = criterion(output, y)\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_acc += (output.argmax(dim = 1) == y).sum()\n",
    "    return total_acc.item()/len(loader.dataset), total_loss.item()/len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_val = 1e18\n",
    "for epoch in range(PARTS * 121):\n",
    "    if epoch % 20 == 0:\n",
    "        best_loss_val = 1e18\n",
    "    copium = epoch // 20\n",
    "    stx = (copium // 11) * 3\n",
    "    sty = (copium % 11) * 3\n",
    "    print(stx, sty)\n",
    "    train_loader, validation_loader = generate_loaders(epoch % PARTS)\n",
    "    acc_train, loss_train = train_epoch(train_loader, True)\n",
    "    with torch.no_grad():\n",
    "        acc_val, loss_val = train_epoch(validation_loader, False)\n",
    "    print(f\"Epoch {epoch+1}: {acc_train = } {loss_train = } {acc_val = } {loss_val = }\")\n",
    "    if best_loss_val > loss_val:\n",
    "        print(f\"Saving model: {best_loss_val = } > {loss_val = }\")\n",
    "        best_loss_val = loss_val\n",
    "        torch.save(model.state_dict(), './data/' + f'{copium}' 'model_dict.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "import torchvision.datasets\n",
    "\n",
    "test = torchvision.datasets.MNIST(\n",
    "    root = \"./data\",\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = dataset_transform\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "test_loader = DataLoader(test, batch_size = BATCH_SIZE, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    acc_test, loss_test = train_epoch(test_loader, False)\n",
    "\n",
    "print(f\"{acc_test = }, {loss_test = }\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model.load_state_dict(torch.load('./data/model_dict.pt'))\n",
    "\n",
    "random_input = torch.rand(1, 1, *IMAGE_SIZE).to(DEVICE)\n",
    "script_module = torch.jit.trace(model, random_input)\n",
    "\n",
    "script_module.save('./data/model_exported.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
